{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff7e1b9d",
   "metadata": {},
   "source": [
    "# Teoria Sprint 5. METODES DE MOSTREIG\n",
    "SOURCES: https://catalogofbias.org/  <br>\n",
    "https://towardsdatascience.com/the-5-sampling-algorithms-every-data-scientist-need-to-know-43c7bc11d17c\n",
    "\n",
    "## - TYPES ---------------------------------------------------------------------------------\n",
    "### A) Probability sampling\n",
    "Using random selection to choose the sample.\n",
    "#### <b><span class=\"mark\">1. Simple random sampling</span></b><br>\n",
    "Fully randomly, we pick the sample from the population with no criteria nor previous sort."
   ]
  },
  {
   "cell_type": "raw",
   "id": "84e03a0c",
   "metadata": {},
   "source": [
    "sample_df = df.sample(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b658f81f",
   "metadata": {},
   "source": [
    "#### <b><span class=\"mark\">2. Systematic sampling</span></b><br>\n",
    "Every member of the population is listed with a number, but instead of randomly generating numbers, individuals are chosen at regular intervals."
   ]
  },
  {
   "cell_type": "raw",
   "id": "433d3acc",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c8a718",
   "metadata": {},
   "source": [
    "#### 3. Stratified sampling\n",
    "You divide the population into subgroups (called strata) based on the relevant characteristic (e.g. gender, age range, income bracket, job role). Then you use random or systematic sampling to select a sample from each subgroup.\n",
    "\n",
    "#### 4. Cluster sampling\n",
    "Cluster sampling also involves dividing the population into subgroups, but instead of sampling individuals from each subgroup, you randomly select entire subgroups. Example: The company has offices in 10 cities across the country (all with roughly the same number of employees in similar roles). You don’t have the capacity to travel to every office to collect your data, so you use random sampling to select 3 offices – these are your clusters.\n",
    "\n",
    "### B) Non-probability sampling\n",
    "Not picking a sample by random criteria, but based on one.\n",
    "#### 1. Convenience sampling\n",
    "A convenience sample simply includes the individuals who happen to be most accessible to the researcher.\n",
    "\n",
    "#### 2. Voluntary response sampling\n",
    "Similar to a convenience sample, but instead of the researcher choosing participants and directly contacting them, people volunteer themselves.\n",
    "\n",
    "#### 3. Purposive (judgement) sampling\n",
    "Example: you want to know more about the opinions and experiences of disabled students at your university, so you <b>purposefully select </b> a number of students with different support needs in order to gather a varied range of data on their experiences with student services.\n",
    "\n",
    "#### 4. Snowball sampling\n",
    "If the population is hard to access, snowball sampling can be used to recruit participants via other participants.\n",
    "Example: you are researching experiences of homelessness in your city. Since there is no list of all homeless people in the city, probability sampling isn’t possible. You meet one person who agrees to participate in the research, and she puts you in contact with other homeless people that she knows in the area.\n",
    "\n",
    "### C) OTHER\n",
    "#### 1. Undersampling and Oversampling\n",
    "Resampling consists of removing samples from the majority class (<b>under-sampling</b>) and/or adding more examples from the minority class (<b>over-sampling</b>).\n",
    "##### a) Undersampling and Oversampling using simple random sampling"
   ]
  },
  {
   "cell_type": "raw",
   "id": "418f8643",
   "metadata": {},
   "source": [
    "#Let us first create some example imbalanced data.\n",
    "from sklearn.datasets import make_classification\n",
    "X, y = make_classification(\n",
    "    n_classes=2, class_sep=1.5, weights=[0.9, 0.1],\n",
    "    n_informative=3, n_redundant=1, flip_y=0,\n",
    "    n_features=20, n_clusters_per_class=1,\n",
    "    n_samples=100, random_state=10\n",
    ")\n",
    "X = pd.DataFrame(X)\n",
    "X['target'] = y\n",
    "\n",
    "#We can now do random oversampling and undersampling using:\n",
    "num_0 = len(X[X['target']==0])\n",
    "num_1 = len(X[X['target']==1])\n",
    "print(num_0,num_1)\n",
    "\n",
    "# random undersample\n",
    "undersampled_data = pd.concat([ X[X['target']==0].sample(num_1) , X[X['target']==1] ])\n",
    "print(len(undersampled_data))\n",
    "\n",
    "# random oversample\n",
    "oversampled_data = pd.concat([ X[X['target']==0] , X[X['target']==1].sample(num_0, replace=True) ])\n",
    "print(len(oversampled_data))\n",
    "------------------------------------------------------------\n",
    "OUTPUT:\n",
    "90 10\n",
    "20\n",
    "180"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1d7c14",
   "metadata": {},
   "source": [
    "##### b) Undersampling and Oversampling using IMBLEARN\n",
    "IMBALANCED-LEARN (imblearn) is a Python Package to tackle the curse of imbalanced datasets. \n",
    "<br>Further info: https://github.com/scikit-learn-contrib/imbalanced-learn#id3\n",
    "\n",
    "- <b>Undersampling using TOMEK LINKS</b><br>\n",
    "One of such methods it provides is called Tomek Links. Tomek links are pairs of examples of opposite classes in close vicinity."
   ]
  },
  {
   "cell_type": "raw",
   "id": "32c6563e",
   "metadata": {},
   "source": [
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "tl = TomekLinks(return_indices=True, ratio='majority')\n",
    "X_tl, y_tl, id_tl = tl.fit_sample(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec34c8e",
   "metadata": {},
   "source": [
    "- <b><span class=\"mark\">Synthetic Minority Oversampling Technique (SMOTE)</span></b><br>\n",
    "When a minority is likely to not being reflected in a statistics analysis, we might wanna give it a bit more of weight to include its value in the conclusions drawn from it. The SMOTE method creates 'fake' observations similar to the real ones from the minority, so it feels like the minority is not so minor in the analysis."
   ]
  },
  {
   "cell_type": "raw",
   "id": "3ceeee90",
   "metadata": {},
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(ratio='minority')\n",
    "X_sm, y_sm = smote.fit_sample(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f68ffb",
   "metadata": {},
   "source": [
    "#### <b><span class=\"mark\">2. Reservoir sampling</span></b><br>\n",
    "Used in data mining to obtain a sample of size n from a data stream of unknown length."
   ]
  },
  {
   "cell_type": "raw",
   "id": "b51aa9bb",
   "metadata": {},
   "source": [
    "import random\n",
    "def generator(max):\n",
    "    number = 1\n",
    "    while number < max:\n",
    "        number += 1\n",
    "        yield number\n",
    "# Create as stream generator\n",
    "stream = generator(10000)\n",
    "# Doing Reservoir Sampling from the stream\n",
    "k=5\n",
    "reservoir = []\n",
    "for i, element in enumerate(stream):\n",
    "    if i+1<= k:\n",
    "        reservoir.append(element)\n",
    "    else:\n",
    "        probability = k/(i+1)\n",
    "        if random.random() < probability:\n",
    "            # Select item in stream and remove one of the k items already selected\n",
    "             reservoir[random.choice(range(0,k))] = element\n",
    "print(reservoir)\n",
    "------------------------------------\n",
    "[1369, 4108, 9986, 828, 5589]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555c6c64",
   "metadata": {},
   "source": [
    "## - METHODS ---------------------------------------------------------------------------------\n",
    "#### Step 1: Was the study sampled from individuals?\n",
    "Then we might be talking about <b>simple random sampling</b> or <b>sistematic sampling</b>\n",
    "\n",
    "#### Step 2: Was the study sampled from groups? \n",
    "If yes:\n",
    "\n",
    "#### Step 3: Does the study have data about the individuals or not?\n",
    "If yes, we might be in front of a <b>stratified sampling</b>. Otherwise, we might only have info about groups (such as schools, or towns) were we picked samples from. In that case we are talking about a <b>cluster sampling</b>.\n",
    "\n",
    "#### Step 4: Was the sample easy to get?\n",
    "In that case there might've been used the <b>convenience sampling</b> method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774c24dc",
   "metadata": {},
   "source": [
    "## - SAMPLING ERROR ---------------------------------------------------------------------------------\n",
    "It’s the difference between the statistic you measure and the parameter you would find if you took a census of the entire population. Since studying the whole population it's sometimes impossible because it's too big, the error we get from a sample is always expected. However, if it's lower than 3% we call it acceptable. <br>In order to avoid sampling error, we shall increase the size of the sample. That's way surveys normally take the size of thousands. <br><br>But at the same time, an statistical study could have an error differentiating the sample too far from the population, yet not being a sampling error. In this case we talk about <b>non-sampling error</b>. <br>This is due to poor data collection methods (like faulty instruments or inaccurate data recording), selection bias, non response bias (where individuals don’t want to or can’t respond to a survey), or other mistakes in collecting the data. Increasing the sample size will not reduce these errors. They key is to avoid making the errors in the first place with a well-planned design for the survey or experiment.\n",
    "\n",
    "<br><br>Let's dive a bit deeper into the most common BIAS that can drive to sampling and non-sampling errors:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140109b4",
   "metadata": {},
   "source": [
    "## - BIAS CATALOG --------------------------------------------------------------------------------------\n",
    "### A) SELECTION BIAS\n",
    "Occurs when the individuals or groups taken in a study are systematically different than the population from the beginning, leading to a systematic error in the outcome. Error when selecting the sample (it doesn't represent well the population which could overstate/understate some groups).<br>\n",
    "#### 1. COLLIDER BIAS\n",
    "Mistaking coincidence for causality. If A causes X, and B also causes X, A and B are related? We'd better dive a bit more on that study if we want to avoid collider bias...\n",
    "\n",
    "#### 2. CONFOUNDING BIAS\n",
    "Similar to the collider bias, confounding bias is distortion that modifies an association between an exposure and an outcome because a factor is independently associated with the exposure and the outcome. Though this time X causes A and B, so the wrong assumption is that A and B are related.\n",
    "\n",
    "#### 3. ASCERTAINMENT BIAS\n",
    "Systematic differences in the identification of individuals included in a study or distortion in the collection of data in a study.\n",
    "\n",
    "#### 4. ATTRITION BIAS\n",
    "Unequal loss of participants from study groups in a trial.\n",
    "\n",
    "### B) CONDUCT BIAS\n",
    "#### 1. HAWTHORNE EFFECT\n",
    "When individuals modify an aspect of their behaviour in response to their awareness of being observed. Preventive steps: Studies using hidden observation can help avoid the Hawthorne effect.\n",
    "\n",
    "#### 2. RECALL BIAS\n",
    "Systematic error due to differences in accuracy or completeness of recall to memory of past events or experiences.\n",
    "\n",
    "#### 3. AVAILABILITY BIAS\n",
    "A distortion that arises from the use of information which is most readily available, rather than that which is necessarily most representative.\n",
    "\n",
    "### C) CONCEPTUALIZATION BIAS\n",
    "#### 1. INMORTAL TIME BIAS\n",
    "A distortion that modifies an association between an exposure and an outcome, caused when a cohort study is designed so that follow-up includes a period of time where participants in the exposed group cannot experience the outcome and are essentially ‘immortal’.\n",
    "\n",
    "### D) REPORTING BIAS\n",
    "#### 1. INFORMATION BIAS\n",
    "Bias that arises from systematic differences in the collection, recall, recording or handling of information used in a study. \n",
    "\n",
    "Availability bias\n",
    "A distortion that arises from the use of information which is most readily available, rather than that which is necessarily most representative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362dc2f1",
   "metadata": {},
   "source": [
    "## - STATISTICAL STUDIES-----------------------------------------------------------------------------\n",
    "### 1. Sample study\n",
    "You extract a sample from a population to try to estimate a parameter of it.\n",
    "### 2. Observation study\n",
    "You are seeing if there's a correlation between two parameters of a dataset. Don't mistake for causality.\n",
    "### 3. Experiment \n",
    "You are trying to show causality between two parameters of a sample/population (namely, if the <b>explanatory variable</b> triggers an specific <b>response variable</b>), and you do so by divind the experiment sample in two groups: one is the <b>control group</b> and the other the <b>treatment group</b>. You'll put the treatment group under experiment, leaving the control one under a 'normal' situation. Then you compare results. <br>\n",
    "<b>Experimental units</b> are those subjects being tested in the experiments (persons, animals, bacteries, etc.)\n",
    "<br><b>Matched pairs design</b> is the technique to run an experiment twice, swtiching the control group and the experiment group, in order to dilute any bias.\n",
    "<br>In a <b>blind experiment</b> the experimental units don't know wether they are getting the medicine or the placebo. In a <b>double-blind experiment</b> nor the experimental units or the administrator of the pills are aware of wether a pill is placebo or medicine. Finally, in a <b>triple-blind experiment</b> not even the analysts of the experiment know how to differentiate placebo or medicine.\n",
    "#### - Types of experiment design:\n",
    "<b>1. Completely randomized: </b>using simple random sampling<br>\n",
    "<b>2. Matched pairs: </b>grouping the sample by pairs first, then randomly sending each first of the pairs to the control group and the other to the treatment group<br>\n",
    "<b>3. Randomized block: </b>using stratified sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd32516",
   "metadata": {},
   "source": [
    "## - SAMPLING PROCESS -----------------------------------------------------------------------------\n",
    "### Step 1. Identify and define target population\n",
    "Only the people above 18 yo. that can vote.\n",
    "### Step 2. Select sampling frame\n",
    "List of all people on the voter list.\n",
    "### Step 3. Choose sampling methods\n",
    "Consider each vote values the same. Probability will then be related to the number of votes a party has.\n",
    "### Step 4. Determine sample size\n",
    "From all the population, how many people will we take as the sample (not as large that would be cumbersome, but as little that the conclusion can't be accurately applied to the population)\n",
    "### Step 5. Collect the required Data\n",
    "Using the most appropiate sampling technique."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
